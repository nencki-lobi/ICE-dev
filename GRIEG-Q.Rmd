---
title: "GRIEG questionnaire data analysis"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(knitr.kable.NA = '')

library(knitr)
library(dplyr)
library(psych)
library(doBy)
library(EFA.dimensions)
library(stringr)
```

## Preparatory steps

### Load items

We load the `items.tsv` file, which stores the information on the content of the questionnaire items. The file contains unique item codes, as well as item text in Polish and English.
 
```{r}
items =  read.table ("./input/items.tsv", header = T, sep = "\t", encoding="UTF-8")
```

### Load data

We load the input data from three surveys (`survey176496`, `survey381735`, and `survey977613`). The structure of each file is (almost) identical (number of columns differ, names of some of the columns differ). The files contain demographical data of participants, as well as responses to questionnaire items.

```{r}
input1 = read.table ("./input/176496/results-survey176496.csv", header = T, sep = ",", encoding="UTF-8")
input2 = read.table ("./input/381735/results-survey381735.csv", header = T, sep = ",", encoding="UTF-8")
input3 = read.table ("./input/977613/results-survey977613.csv", header = T, sep = ",", encoding="UTF-8")
```

`survey176496` and `survey381735` contain data from the general population (recruited by professional recruitment company), and `survey977613` contains data from climate activists (recruited via social media). 

### Clean data based on quality check criteria

We clean the data based on previously performed quality check analysis. In this analysis we used the following criteria:

* consistent reporting of demographic data (sex, age)
* correct responses to 2 out of 3 control questions

As this is currently implemented in other, external script (written in MATLAB), we will import additional `.csv` files that contain lists of valid tokens for each survey and we will use this information to filter the data.

**NOTE:** This step is applicable only to `survey176496` and `survey381735`. Therefore, we leave `survey977613` intact. 

```{r}
valid1 = read.table ("./input/176496/valid.csv", header = T, sep = "\t", encoding="UTF-8")
valid2 = read.table ("./input/381735/valid.csv", header = T, sep = "\t", encoding="UTF-8")

dataset1 = filter(input1,token %in% valid1$token)
dataset2 = filter(input2,token %in% valid2$token)
dataset3 = input3
```

### Combine data

Next, we need to combine the datasets.

We are only interested in keeping columns that contain relevant data (questionnaire items). These data is stored in columns `14:184` in the case of `dataset1` and `dataset2`, but in columns `13:183` in the case of `dataset3`.

``` {r}
colnames(dataset1[,14:184])
```

Therefore, we combine the datasets keeping only relevant columns.

```{r}
dataset = rbind(dataset1[,14:184], dataset2[,14:184], dataset3[,13:183])
```

### Convert data

Next, we need to recode the data to a format more suitable for the analysis.

First, we need to remove any whitespaces present in the data.

```{r}
dataset = as.data.frame(apply(dataset,2,str_trim))
```

Second, the imported data is in `char` format. We need to recode it to either `factor` or `int`.

``` {r}
# recode to `factor` (categorical):
# dataset = dataset %>%
#   mutate_at(vars(1:171),
#             ~factor(recode(.,
#                            "Zdecydowanie nie" = 1,
#                            "Raczej nie " = 2,
#                            "Ani tak, ani nie" = 3,
#                            "Raczej tak " = 4,
#                            "Zdecydowanie tak" = 5)), ordered = TRUE)

# recode to `int` (numeric)
dataset = dataset %>%
  mutate_at(vars(1:171),
            list(~recode(.,
                           "Zdecydowanie nie" = 1,
                           "Raczej nie" = 2,
                           "Ani tak, ani nie" = 3,
                           "Raczej tak" = 4,
                           "Zdecydowanie tak" = 5)))
```

### Clean data based on variance of responses

Next, we clean the data based on the standard deviations (SDs) of participants' responses. Since items were presented in blocks, it should be most informative to investigate SDs within each block.

Hence, we first identify items belonging to each block. Here, we discard control questions (`CHECK`), because even participants who contributed poor quality data (Polish: _klikacze_) could have made the effort to respond correctly to control questions.

``` {r}
BLOCK1 = select(dataset, contains('BLOCK1.') & !contains("CHECK"))
BLOCK2 = select(dataset, contains('BLOCK2.') & !contains("CHECK"))
BLOCK3 = select(dataset, contains('BLOCK3.') & !contains("CHECK"))
BLOCK4 = select(dataset, contains('BLOCK4.') & !contains("CHECK"))
BLOCK5 = select(dataset, contains('BLOCK5.') & !contains("CHECK"))
BLOCK6 = select(dataset, contains('BLOCK6.') & !contains("CHECK"))
BLOCK7 = select(dataset, contains('BLOCK7.') & !contains("CHECK"))
BLOCK8 = select(dataset, contains('BLOCK8.') & !contains("CHECK"))
BLOCK9 = select(dataset, contains('BLOCK9.') & !contains("CHECK"))
BLOCK10 = select(dataset, contains('BLOCK10.') & !contains("CHECK"))
BLOCK11 = select(dataset, contains('BLOCK11.') & !contains("CHECK"))
BLOCK12 = select(dataset, contains('BLOCK12.') & !contains("CHECK"))
BLOCK13 = select(dataset, contains('BLOCK13.') & !contains("CHECK"))
BLOCK14 = select(dataset, contains('BLOCK14.') & !contains("CHECK"))
```

Then, for each block separately we identify "good" participants, that is participants with nonzero variance in responses. This results with 14 lists of indices that represent good participants in each block.

``` {r}
BLOCKS = list(BLOCK1, BLOCK2, BLOCK3, BLOCK4, BLOCK5, BLOCK6, BLOCK7, BLOCK8, BLOCK9, BLOCK10, BLOCK11, BLOCK12, BLOCK13, BLOCK14)

good = NULL
for (i in 1:length(BLOCKS)) {
  SD = apply(BLOCKS[[i]], 1, sd) # compute SD for each participant
  good[i] = list(which(SD != 0)) # find participants with nonzero variance
  cat(sprintf("BLOCK%s: %s participants with nonzero variance \n", i, length(good[[i]])))
}
```

As you can see above, the list of good participants will differ from one block to the other. To identify participants with nonzero variance across blocks, we need to intersect those 14 lists.

```{r}
allgood = Reduce(intersect, good)
```

We can now clean the dataset:

```{r}
dataset = dataset[allgood,]
```

### Organize item information

Furthermore, we create three additional variables, which we will later use to extract relevant information about the items. 

`code_to_pl` returns the item's original text in Polish.

```{r}
code_to_pl = items$subquestion
names(code_to_pl) = items$code
```

`code_to_en` returns the item's text translated into English.

```{r}
code_to_en = items$subquestion_ENG
names(code_to_en) = items$code
```

`code_to_block` returns the number of the block, in which the given item was displayed.

```{r}
code_messy = colnames(dataset)
code_splitted = strsplit(code_messy, ".", fixed = TRUE)
code_flattened = as.data.frame(do.call(rbind, code_splitted))
colnames(code_flattened) = c("block","code")

code_to_block = code_flattened$block
names(code_to_block) = code_flattened$code
```

## Reliability analysis {.tabset}

We want to identify items that best represent a given emotion construct (e.g. anger). Specifically, for each item we want to assess how well it correlates with all the other items representing the same emotion construct. 

Thus, we first need to split the data according to emotions.

``` {r}
ANG = select(dataset,contains('.ANG')) # Anger
APP = select(dataset,contains('.APP')) # Apprehension
EMP = select(dataset,contains('.EMP')) # Empowerment
GUI = select(dataset,contains('.GUI')) # Guilt
HOPF = select(dataset,contains('.HOPF')) # Hopefulness
HOPL = select(dataset,contains('.HOPL')) # Hopelessness
IRR = select(dataset,contains('.IRR')) # Irritation
ISO = select(dataset,contains('.ISO')) # Isolation
POWL = select(dataset,contains('.POWL')) # Powerlessness
SOR = select(dataset,contains('.SOR')) # Sorrow

DIS = select(dataset,contains('.DIS')) # Discontent
IND = select(dataset,contains('.IND')) # Indifference
```

We assess the reliability, by calculating Cronbach's alpha for each emotion separately. Use the tabs below to switch between the results for each emotion.

``` {r, results='asis'}
EMOTIONS = list(ANG, APP, EMP, GUI, HOPF, HOPL, IRR, ISO, POWL, SOR, DIS, IND)
labels = list("Anger", "Apprehension", "Empowerment", "Guilt",
              "Hopefulness", "Hopelessness", "Irritation", "Isolation",
              "Powerlessness", "Sorrow", "Discontent", "Indifference")

for (i in 1:length(EMOTIONS)) {
  
  out = alpha(EMOTIONS[[i]]) # Cronbach's alpha
  
  cat("\n")
  cat(sprintf("### %s \n", labels[[i]]))
  cat("\n")
  
  cat(sprintf("\n Reliability analysis:"))
  print(kable(out$total, digits = 2))
  
  cat(sprintf("\n Reliability if an item is dropped:"))
  print(kable(out$alpha.drop, digits = 2))
  
  cat(sprintf("\n Item statistics:"))
  print(kable(out$item.stats, digits = 2))
  
  cat(sprintf("\n Non missing response frequency for each item:"))
  print(kable(out$response.freq, digits = 2))
  
  cat("\n")
}
```

## Exploratory factor analysis (EFA)

### Correlation matrix

Before we proceed to the exploratory factor analysis (EFA), we need to create a correlation matrix that will be used in subsequent steps.

**NOTE:** We use `polychoric` correlations!

``` {r}
cor_matrix = POLYCHORIC_R(dataset, method = "Fox", verbose = F)
```

### Diagnostic tests

Next, we run necessary diagnostic tests to make sure that our data are suitable for EFA.

First, we run the **Bartlett's test**, which checks whether a correlation matrix is factorable.

``` {r}
cortest.bartlett(cor_matrix, n=200)
```

Second, we run the **Kaiser-Meyer-Olkin (KMO) test**, which provides a measure of sampling adequacy (MSA).

``` {r}
KMO(cor_matrix)
```

Both tests confirm that our data are suitable for EFA.

### Decision on the number of factors

Next, we need to decide on the number of factors to extract. We use `RAWPAR`, that is parallel analysis of eigenvalues ([Horn, 1965](https://link.springer.com/article/10.1007/BF02289447)).

The parallel analysis procedure for deciding on the number of components or factors involves extracting eigenvalues from random data sets that parallel the actual data set with regard to the number of cases and variables. For example, if the original data set consists of 620 observations for each of 171 variables, then a series of random data matrices of this size (620 by 171) would be generated, and eigenvalues would be computed for the correlation matrices for the original, real data and for each of the random data sets. The eigenvalues derived from the actual data are then compared to the eigenvalues derived from the random data.  In Horn's original description of this procedure, the mean eigenvalues from the random data served as the comparison baseline, whereas the more common current practice is to use the eigenvalues that correspond to the desired percentile (typically the 95th) of the distribution of random data eigenvalues. Factors or components are retained as long as the ith eigenvalue from the actual data is greater than the ith eigenvalue from the random data.

**NOTE:** For the final report we should use `Ndatasets = 10000`.

**NOTE:** We use `polychoric` correlations!

``` {r}
#RAWPAR(cor_matrix, randtype = "permuted", Ndatasets=1000, factormodel="PCA", percentile=95, corkindRAND="polychoric", verbose=T, Ncases=nrow(dataset))
```

### Factor analysis

Finally, we can proceed to the exploratory factor analysis (EFA). We assume the number of factors to extract based on the result of the `RAWPAR` analysis.

**NOTE:** We use `polychoric` correlations!

``` {r, message = FALSE, results = 'hide'}
PA = PA_FA(cor_matrix, Nfactors=6, iterpaf=250, rotate="none", verbose=T, Ncases=nrow(dataset))
```

We perform factor rotation in a separate step.

``` {r, message = FALSE, results = 'hide'}
loadings = PA$loadingsNOROT
rotated = PROMAX(loadings, ppower=4, verbose=T)
rotated = rotated$pattern
```

### Thresholding {.tabset}

Based on the factor loadings, we need to decide which items should be included to the final version of the questionnaire.

We clean the output based on two criteria (both criteria must be met):

* `criterion1`: for any item to be included to a given factor, its corresponding factor loading must be greater than a certain threshold value
* `criterion2`: item's factor loading for this factor must be sufficiently higher than its factor loadings for the remaining factors.

This step is done to facilitate the decision process.

We can manipulate `criterion1` and `criterion2` in the code below, to see how many items end up loading each factor at different threshold values.

``` {r, echo=FALSE}
#rotated = ifelse(abs(rotated) > 0.4, rotated, NA)
#kable(rotated)
```

``` {r}
thresholded = matrix(, nrow = nrow(rotated), ncol = ncol(rotated))
colnames(thresholded) = colnames(rotated)
rownames(thresholded) = rownames(rotated)

for (i in 1:nrow(rotated)) {
  
  tmp = unname(rotated[i,])
  
  idx = which.maxn(abs(tmp), n = 2)
  max1 = idx[1]
  max2 = idx[2]
  
  criterion1 = abs(tmp[max1]) > 0.5
  criterion2 = ( abs(tmp[max1]) - abs(tmp[max2]) ) > 0.3
  
  test = rep(FALSE, length(tmp))
  test[max1] = criterion1 & criterion2
  
  thresholded[i,] = ifelse(test, tmp, NA)
}
```

Assuming the above criteria, the resulting number of items in each factor is as follows:

```{r}
nitems = matrix(nrow = 1, ncol = ncol(thresholded))
colnames(nitems) = colnames(thresholded)
rownames(nitems) = "Number of items"

for (i in 1:ncol(thresholded)) {
  nitems[1,i] = sum(!is.na(thresholded[,i]))
}

kable(nitems)
```

The table below displays the factor loadings that passed the above criteria. Use the tabs below to switch between thresholded and unthresholded views.

#### Thresholded

``` {r}
kable(thresholded, digits = 2)
```

#### Unthresholded

``` {r}
kable(rotated, digits = 2)
```

``` {r}

```

## Note

```{r, echo=FALSE}
# use this block, to print output only (no r syntax)
```

Note that the `echo = FALSE` parameter was added to some of the R code chunks to prevent them from printing.
