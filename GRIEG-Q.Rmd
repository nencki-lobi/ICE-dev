---
title: "GRIEG questionnaire data analysis"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(psych)
library(EFA.dimensions)
```

## Load data

We start by loading the input data. We have data from three surveys (`survey176496`, `survey381735`, and `survey977613`), each with (almost) identical structure (number of columns differ, names of some of the columns differ).

```{r}
input1 = read.table ("./input/176496/results-survey176496.csv", header = T, sep = ",")
input2 = read.table ("./input/381735/results-survey381735.csv", header = T, sep = ",")
input3 = read.table ("./input/977613/results-survey977613.csv", header = T, sep = ",")
```

`survey176496` and `survey381735` contain data from the general population (recruited by professional recruitment company), and `survey977613` contains data from climate activists (recruited via social media). 

## Filter data

Moreover, we want to filter the data based on previously performed quality check analysis. In this analysis we used the following criteria:

* consistent reporting of demographic data (sex, age)
* correct responses to 2 out of 3 control questions

As this is currently implemented in other script (written in MATLAB), we will import additional `.csv` files that contain lists of valid tokens for each survey and we will use this information to filter the data.

**NOTE:** This step is applicable only to `survey176496` and `survey381735`. Therefore, we leave `survey977613` intact. 

```{r}
valid1 = read.table ("./input/176496/valid.csv", header = T, sep = "\t")
valid2 = read.table ("./input/381735/valid.csv", header = T, sep = "\t")

dataset1 = filter(input1,token %in% valid1$token)
dataset2 = filter(input2,token %in% valid2$token)
dataset3 = input3
```

## Combine data

Next, we need to combine the datasets.

We are only interested in keeping columns that contain relevant data (questionnaire items). These data is stored in columns `14:184` in the case of `dataset1` and `dataset2`, but in columns `13:183` in the case of `dataset3`.

``` {r}
colnames(dataset1[,14:184])
```

Therefore, we combine the datasets keeping only relevant columns. Also, let's convert the final dataset to `dataframe` for convenience.

```{r}
dataset = rbind(dataset1[,14:184], dataset2[,14:184], dataset3[,13:183])
dataset = data.frame(dataset)
```

## Convert data

Initially, the imported data is in `char` format. We need to use a format more suitable for the analysis (either `factor` or `int`):

``` {r}
# recode to `factor` (categorical):
dataset = dataset %>%
  mutate_at(vars(1:171),
            ~factor(recode(.,
                           "Zdecydowanie nie" = 1,
                           "Raczej nie " = 2,
                           "Ani tak, ani nie" = 3,
                           "Raczej tak " = 4,
                           "Zdecydowanie tak" = 5)), ordered = TRUE)

# recode to `int` (numeric):
# dataset = dataset %>%
#   mutate_at(vars(1:171),
#             list(~recode(.,
#                            "Zdecydowanie nie" = 1,
#                            "Raczej nie " = 2,
#                            "Ani tak, ani nie" = 3,
#                            "Raczej tak " = 4,
#                            "Zdecydowanie tak" = 5)))
```

## Data cleaning

To perform additional cleaning of the data we look at the standard deviations (SDs) of participants' responses. Since items were presented in blocks, it should be most informative to investigate SDs within each block.

Hence, we first identify items belonging to each block. Here, we discard control questions (`CHECK`), since even participants who contributed poor quality data (pol. _klikacze_) could have made the effort to respond correctly to control questions.

``` {r}
BLOCK1 = select(dataset, contains('BLOCK1.') & !contains("CHECK"))
BLOCK2 = select(dataset, contains('BLOCK2.') & !contains("CHECK"))
BLOCK3 = select(dataset, contains('BLOCK3.') & !contains("CHECK"))
BLOCK4 = select(dataset, contains('BLOCK4.') & !contains("CHECK"))
BLOCK5 = select(dataset, contains('BLOCK5.') & !contains("CHECK"))
BLOCK6 = select(dataset, contains('BLOCK6.') & !contains("CHECK"))
BLOCK7 = select(dataset, contains('BLOCK7.') & !contains("CHECK"))
BLOCK8 = select(dataset, contains('BLOCK8.') & !contains("CHECK"))
BLOCK9 = select(dataset, contains('BLOCK9.') & !contains("CHECK"))
BLOCK10 = select(dataset, contains('BLOCK10.') & !contains("CHECK"))
BLOCK11 = select(dataset, contains('BLOCK11.') & !contains("CHECK"))
BLOCK12 = select(dataset, contains('BLOCK12.') & !contains("CHECK"))
BLOCK13 = select(dataset, contains('BLOCK13.') & !contains("CHECK"))
BLOCK14 = select(dataset, contains('BLOCK14.') & !contains("CHECK"))
```

Next, for each block separately we identify "good" participants, that is participants with nonzero variance. This results with 14 lists of indicies that represent good participants in each block.

``` {r}
BLOCKS = list(BLOCK1, BLOCK2, BLOCK3, BLOCK4, BLOCK5, BLOCK6, BLOCK7, BLOCK8, BLOCK9, BLOCK10, BLOCK11, BLOCK12, BLOCK13, BLOCK14)

good = NULL
for (i in 1:length(BLOCKS)) {
  SD = apply(BLOCKS[[i]], 1, sd) # compute SD for each participant
  good[i] = list(which(SD != 0)) # find participants with nonzero variance
  #print(length(good[[i]]))
  cat(sprintf("BLOCK%s: %s participants with nonzero variance \n", i, length(good[[i]])))
}
```

As you can see above, the list of good participants will differ from one block to the other. To identify participants with nonzero variance across blocks, we need to intersect those 14 lists.

```{r}
allgood = Reduce(intersect, good)
```

We can now clean the dataset:

```{r}
dataset = dataset[allgood,]
```

## Reliability analysis

We want to identify items that best represent a given emotion construct (e.g. anger). Specifically, for each item we want to assess how well it correlates with all the other items representing the same emotion construct. 

Thus, we first need to split the data according to emotions.

``` {r}
ANG = select(dataset,contains('.ANG')) # anger
APP = select(dataset,contains('.APP')) # apprehension
EMP = select(dataset,contains('.EMP')) # empowerment
GUI = select(dataset,contains('.GUI')) # guilt
HOPF = select(dataset,contains('.HOPF')) # hopefulness
HOPL = select(dataset,contains('.HOPL')) # hopelessness
IRR = select(dataset,contains('.IRR')) # irritation
ISO = select(dataset,contains('.ISO')) # isolation
POWL = select(dataset,contains('.POWL')) # powerlessness
SOR = select(dataset,contains('.SOR')) # sorrow

DIS = select(dataset,contains('.DIS')) # discontent
IND = select(dataset,contains('.IND')) # indifference
```

Let's start by inspecting the anger items:

``` {r}
str(ANG)
```

``` {r}

```

## Note

```{r, echo=FALSE}
# use this block, to print output only (no r syntax)
```

Note that the `echo = FALSE` parameter was added to some of the R code chunks to prevent them from printing.
