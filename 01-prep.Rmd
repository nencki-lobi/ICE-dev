## 01. Preparatory steps

```{r, include=FALSE}
set.seed(2137) # set seed for replicability
```

### Load inputs

We load the `items.tsv` file, which stores the information on the content of the questionnaire items. The file contains unique item codes, as well as item text in Polish and English.
 
```{r}
items =  read.table("./01/input/items.tsv", header = T, sep = "\t", encoding = "UTF-8")
```

We load the input data from three surveys (`survey176496`, `survey381735`, and `survey977613`). The structure of each file is (almost) identical (number of columns differ, names of some of the columns differ). The files contain demographical data of participants, as well as responses to questionnaire items.

```{r}
input1 = read.table("./01/input/176496/results-survey176496.csv", header = T, sep = ",", encoding = "UTF-8")
input2 = read.table("./01/input/381735/results-survey381735.csv", header = T, sep = ",", encoding = "UTF-8")
input3 = read.table("./01/input/977613/results-survey977613.csv", header = T, sep = ",", encoding = "UTF-8")
```

`survey176496` and `survey381735` contain data from the general population (recruited by professional recruitment company), and `survey977613` contains data from climate activists (recruited via social media).

Furthermore, in the case of `survey176496` and `survey381735` we use unique token codes to identify participants that the company confirmed to have recruited.

First, we remove any duplicated tokens. If more than two participants used the same token code, we keep the last entry.

```{r}
input1 = filter(input1, !duplicated(input1['token'], fromLast = T))
input2 = filter(input2, !duplicated(input2['token'], fromLast = T))
```

Next, we load additional `recruited*.csv` files that list participants (their tokens) recruited by the company. We use this information to filter out `survey176496` and `survey381735`.

```{r}
recruited1 = read.table("./01/input/176496/recruited.csv", header = T, sep = "\t", encoding = "UTF-8")
recruited2 = read.table("./01/input/381735/recruited.csv", header = T, sep = "\t", encoding = "UTF-8")

input1 = filter(input1,token %in% recruited1$token)
input2 = filter(input2,token %in% recruited2$token)
```

The resulting sample sizes are as follows:

```{r}
surveys = data.frame(matrix(nrow = 3, ncol = 1))
rownames(surveys) = c("176496", "381735", "977613")
colnames(surveys) = c("N")

surveys["176496",] = nrow(input1)
surveys["381735",] = nrow(input2)
surveys["977613",] = nrow(input3)

kable(surveys)
```

The total number of participants is:  **`r nrow(input1) + nrow(input2) + nrow(input3)` participants**.

### Clean data based on quality criteria

We clean the data based on the following quality criteria:

* correct responses to control questions
* consistent reporting of demographic data (sex, age, climate concern)

The first step (data cleaning based on control questions) is applicable to all surveys. However, incorrect responses to control questions were only identified in the case of `survey176496` and `survey381735`, but not in the case of `survey977613`.

The second step (data cleaning based on demographic information) is applicable to `survey176496` and `survey381735` only. This is because demographic data was compared against data provided by the recruitment company.

Thus, we clean data from `survey176496` and `survey381735` only, and leave `survey977613` intact.

To clean the data, we need to identify those participants (their tokens) that met the above described criteria. As this is currently implemented in other, external script (written in MATLAB), here we only import the files that this script generated. 

The `checks*.csv` files contain information on quality criteria met by each participant.

```{r}
checks1 = read.table("./01/input/176496/checks.csv", header = T, sep = "\t", encoding = "UTF-8")
checks2 = read.table("./01/input/381735/checks.csv", header = T, sep = "\t", encoding = "UTF-8")
```

The number of participants to exclude based on quality criteria is as follows:

``` {r}
checks = matrix(nrow = 3, ncol = 6)
colnames(checks) = c("No correct question", "< 2 correct questions", "< 3 correct questions", "Inconsistent sex", "Inconsistent age", "Inconsistent climate concern")
rownames(checks) = rownames(surveys)

checks[1,] = colSums(!checks1[,-1])
checks[2,] = colSums(!checks2[,-1])
  
surveys = cbind(surveys, checks)
kable(surveys)
```

Depending on how strict we want to be, the total number of participants to exclude is as follows:

```{r}
demo1 = checks1$sex_check & checks1$age_check & checks1$climate_check
demo2 = checks2$sex_check & checks2$age_check & checks2$climate_check

low1 = !(checks1$question_1_check & demo1)
low2 = !(checks2$question_1_check & demo2)

moderate1 = !(checks1$question_2_check & demo1)
moderate2 = !(checks2$question_2_check & demo2)

high1 = !(checks1$question_3_check & demo1)
high2 = !(checks2$question_3_check & demo2)
```

```{r, include=FALSE}
option = "moderate"
nexcluded_quality = sum(moderate1) + sum(moderate2)
```

* `low`: correct responses to at least one control question and consistent demographic data (**`r sum(low1) + sum(low2)` participants** excluded)

* `moderate`: correct responses to at least two control questions and consistent demographic data (**`r sum(moderate1) + sum(moderate2)` participants** excluded)

* `high`: correct responses to all three control questions and consistent demographic data (**`r sum(high1) + sum(high2)` participants** excluded)

Here, we will use the ``r option`` option:

```{r}
dataset1 = filter(input1,token %in% checks1[!moderate1,"token"])
dataset2 = filter(input2,token %in% checks2[!moderate2,"token"])
dataset3 = input3
```

The total number of participants excluded based on quality criteria is:  **`r nexcluded_quality` participants**.

### Combine data

Next, we need to combine the datasets.

We are only interested in keeping columns that contain relevant data (questionnaire items). These data is stored in columns `14:184` in the case of `dataset1` and `dataset2`, but in columns `13:183` in the case of `dataset3`.

``` {r}
colnames(dataset1[,14:184])
```

Therefore, we combine the datasets keeping only relevant columns.

```{r}
dataset = rbind(dataset1[,14:184], dataset2[,14:184], dataset3[,13:183])
```

Also, we remove control questions:

```{r}
dataset = select(dataset, !contains("CHECK"))
```

### Convert data

Next, we need to recode the data to a format more suitable for the analysis.

First, we need to remove any whitespaces present in the data.

```{r}
dataset = as.data.frame(apply(dataset,2,str_trim))
```

Second, the imported data is in `char` format. We need to recode it to either `factor` or `int`.

``` {r}
# recode to `factor` (categorical):
# dataset = dataset %>%
#   mutate_all(~factor(recode(.,
#                            "Zdecydowanie nie" = 1,
#                            "Raczej nie " = 2,
#                            "Ani tak, ani nie" = 3,
#                            "Raczej tak " = 4,
#                            "Zdecydowanie tak" = 5)), ordered = TRUE)

# recode to `int` (numeric)
dataset = dataset %>%
  mutate_all(list(~recode(.,
                           "Zdecydowanie nie" = 1,
                           "Raczej nie" = 2,
                           "Ani tak, ani nie" = 3,
                           "Raczej tak" = 4,
                           "Zdecydowanie tak" = 5)))
```

### Organize item information

Furthermore, we create three additional variables, which we will later use to extract relevant information about the items. 

`code_to_pl` returns the item's original text in Polish.

```{r}
code_to_pl = items$subquestion
names(code_to_pl) = items$code
```

`code_to_en` returns the item's text translated into English.

```{r}
code_to_en = items$subquestion_ENG
names(code_to_en) = items$code
```

`code_to_block` returns the number of the block, in which the given item was displayed.

```{r}
code_messy = colnames(dataset)
code_splitted = strsplit(code_messy, ".", fixed = TRUE)
code_flattened = as.data.frame(do.call(rbind, code_splitted))
colnames(code_flattened) = c("block","code")

code_to_block = code_flattened$block
names(code_to_block) = code_flattened$code
```

### Simplify item codes

This step is used to simplify the item codes in the final dataset (e.g. `SOR11` instead of `BLOCK1.SOR11.`).

```{r}
colnames(dataset) = names(code_to_block)
```

### Save outputs

Save outputs required for further step(s).

``` {r}
save(dataset, code_to_pl, code_to_en, file = "./01/output/dataset.RData")
```
